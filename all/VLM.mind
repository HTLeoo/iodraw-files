{"root":{"data":{"id":"deu7jy5tci00","created":1765336477861,"text":"VLM"},"children":[{"data":{"id":"deu7k7q3xhs0","created":1765336498679,"text":"load_model","layout_mind_offset":{"x":-38.99999941885471,"y":-172.99999742209926}},"children":[{"data":{"id":"deu7kf486c80","created":1765336514770,"text":"vision_backbone[dinov2+siglip],\nimage_transform[dinov2+siglip]","layout_right_offset":{"x":-1.9999999701976776,"y":-62.99999906122687}},"children":[{"data":{"id":"deubr9gqrrc0","created":1765348335455,"text":"dinov2-get_intermediate_layers(image, n=len(blocks)-2)，\nsiglip-与dinov2类似"},"children":[]}]},{"data":{"id":"deu7okdrm6o0","created":1765336839687,"text":"llm_backbone[Llama2-7B],\ntokenizer[]"},"children":[{"data":{"id":"deueflkpz4w0","created":1765355884776,"text":"Tokenizer将输入转化成整数idx,训练需要mask掉后文，预测时则逐token预测，直到达到最大长度或者eos?"},"children":[]}]},{"data":{"id":"deu87ajchmo0","created":1765338307176,"text":"vlm[vision backbone+llm_backbone+projector]"},"children":[]}]},{"data":{"id":"deu7k99n37k0","created":1765336502037,"text":"分支主题","layout_mind_offset":{"x":404.9999939650298,"y":109.99999836087221}},"children":[]},{"data":{"id":"deyksdmqg0w0","created":1765780052704,"text":"LLM","layout_mind_offset":{"x":-46.99999929964554,"y":-187.99999719858164}},"children":[{"data":{"id":"deyksjbzkk80","created":1765780065115,"text":"Llama","expandState":"expand"},"children":[{"data":{"id":"deyksmrz4rs0","created":1765780072612,"text":"Tokenizer-"},"children":[{"data":{"id":"deykv3z2teg0","created":1765780266775,"text":"n_words词库大小\nBOS开始id\nEOS结束id\npadding 填充id","layout_left_offset":{"x":-426.666644414267,"y":6.6666663189728865}},"children":[]},{"data":{"id":"deykw3jnsc80","created":1765780344207,"text":"encode-负责将任意输入转成纯int的id列表，\nencode包含BOS,EOS两个flag，以确认是否在最前面或者最后加上对应的id。\ndecode-将纯int的id列表转换成文本","layout_left_offset":{"x":-249.99998696148464,"y":9.999999478459415}},"children":[]}]},{"data":{"id":"deykxz73wao0","created":1765780491469,"text":"Transformer"},"children":[{"data":{"id":"deyky5a5bo80","created":1765780504714,"text":"embedding-接受vocab_size和embed_dim两个参数，表示维护的词表大小和维度；\n输入是[bsz, len]的token，然后根据词表找到对应的token,得到结果就是[bsz,len,embed_dim]的embeddings","layout_left_offset":{"x":-243.3333349476252,"y":38.99999789976425}},"children":[]},{"data":{"id":"deylixe8eiw0","created":1765782133194,"text":"mask_attention:这里主要接受idx，和mask;\n会额外构造cache-k,cache-v\n推理时，在生成qkv后，对qk进行rope位置编码；\ncache每次只更新最近固定长度的内容；但是kv是逐步增长的；q会根据这个不断增长的k,v生成attention，最后得到结果。","layout_left_offset":{"x":-608.3332774332869,"y":82.49999241903481}},"children":[]},{"data":{"id":"deylzve3q4o0","created":1765783461023,"text":"output，是一个linear层，只对最后一个token计算，输入维度是dim，输出维度是vocab_size；最后这个是一个类似于分类的映射，找到最后是哪个词的概率最大，然后根据argmax可以直接取到对应的embedding；","layout_left_offset":{"x":-209.9999807029974,"y":164.1666515813115}},"children":[]}]}]}]}]},"template":"default","theme":"fresh-blue","version":"1.4.43"}